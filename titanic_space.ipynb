{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd5b8b2-10f5-47c7-861e-acca3a614c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaceship-titanic.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c spaceship-titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2535e8ff-97e3-4ee3-b1d6-b045963c09d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/ypn030093497vyfy0wz4lyqc0000gn/T/ipykernel_49371/1208835502.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf4d8db-f818-45cd-8e67-d12186e7a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I am going for a very simple model with dropping all the nan values and converting the categorical objects into dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e6d44cb6-1469-4c67-b4a8-a7db42b2c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class tit_space(Dataset):\n",
    "    def __init__(self, to_ = 'train'):\n",
    "        df = pd.read_csv(f'spaceship-titanic/{to_}.csv')\n",
    "\n",
    "        df.dropna(inplace = True)\n",
    "        df.drop(['Name', 'PassengerId', 'Cabin'], axis = 1, inplace = True)\n",
    "        df = pd.get_dummies(df, columns = ['HomePlanet', 'Destination'], drop_first = True)\n",
    "        df.replace([False, True], [0,1], inplace = True)\n",
    "        df = (df-df.min())/(df.max() - df.min())\n",
    "        # print(df)\n",
    "        self.label = torch.tensor(df.pop('Transported').to_numpy(), dtype = torch.float)\n",
    "        self.df = torch.tensor(df.to_numpy(), dtype = torch.float)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.df[idx], self.label[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "32af5fd0-d925-4772-9421-e1a51cc53f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CryoSleep       Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
      "0           0.0  0.493671  0.0     0.000000   0.000000      0.000000   \n",
      "1           0.0  0.303797  0.0     0.010988   0.000302      0.002040   \n",
      "2           0.0  0.734177  1.0     0.004335   0.119948      0.000000   \n",
      "3           0.0  0.417722  0.0     0.000000   0.043035      0.030278   \n",
      "4           0.0  0.202532  0.0     0.030544   0.002348      0.012324   \n",
      "...         ...       ...  ...          ...        ...           ...   \n",
      "8688        0.0  0.518987  1.0     0.000000   0.228726      0.000000   \n",
      "8689        1.0  0.227848  0.0     0.000000   0.000000      0.000000   \n",
      "8690        0.0  0.329114  0.0     0.000000   0.000000      0.152779   \n",
      "8691        0.0  0.405063  0.0     0.000000   0.035186      0.000000   \n",
      "8692        0.0  0.556962  0.0     0.012702   0.157247      0.000000   \n",
      "\n",
      "           Spa    VRDeck  Transported  HomePlanet_Europa  HomePlanet_Mars  \\\n",
      "0     0.000000  0.000000          0.0                1.0              0.0   \n",
      "1     0.024500  0.002164          1.0                0.0              0.0   \n",
      "2     0.299670  0.002410          0.0                1.0              0.0   \n",
      "3     0.148563  0.009491          0.0                1.0              0.0   \n",
      "4     0.025214  0.000098          1.0                0.0              0.0   \n",
      "...        ...       ...          ...                ...              ...   \n",
      "8688  0.073322  0.003639          0.0                1.0              0.0   \n",
      "8689  0.000000  0.000000          0.0                0.0              0.0   \n",
      "8690  0.000045  0.000000          1.0                0.0              0.0   \n",
      "8691  0.015753  0.159077          0.0                1.0              0.0   \n",
      "8692  0.000000  0.000590          1.0                1.0              0.0   \n",
      "\n",
      "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  \n",
      "0                           0.0                      1.0  \n",
      "1                           0.0                      1.0  \n",
      "2                           0.0                      1.0  \n",
      "3                           0.0                      1.0  \n",
      "4                           0.0                      1.0  \n",
      "...                         ...                      ...  \n",
      "8688                        0.0                      0.0  \n",
      "8689                        1.0                      0.0  \n",
      "8690                        0.0                      1.0  \n",
      "8691                        0.0                      0.0  \n",
      "8692                        0.0                      1.0  \n",
      "\n",
      "[6606 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/ypn030093497vyfy0wz4lyqc0000gn/T/ipykernel_49371/3488158696.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace([False, True], [0,1], inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.4937, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000, 0.0000, 1.0000]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "tit_data = tit_space()\n",
    "train_dataset, test_dataset = random_split(tit_data, [0.9, 0.1])\n",
    "len(train_dataset), len(test_dataset)\n",
    "tit_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2c5b8aeb-5d8a-4ee9-b18e-6748eee9059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter----\n",
    "\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "epoch = 11\n",
    "batch_eval_inter = 100\n",
    "eval_train_test = 10\n",
    "# eval_test = 10\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "18e81a3a-9e98-488e-85ce-3e1428eb0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9865c9-dd4b-4ec6-987a-940caac99adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5c3473c0-a7ed-40de-97bc-25be4e1276e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "torch.manual_seed(42)\n",
    "class space_finder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(space_finder, self).__init__()\n",
    "        # self.block = nn.Sequential(\n",
    "        #     nn.Linear(12, 100),\n",
    "        #     nn.BatchNorm1d(100),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(100, 200),\n",
    "        #     nn.BatchNorm1d(200),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(200, 500),\n",
    "        #     nn.BatchNorm1d(100),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(100, 50),\n",
    "        #     nn.BatchNorm1d(50),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(50, 1),\n",
    "        # )\n",
    "        self.l1 = nn.Sequential(\n",
    "                nn.Linear(12, ),\n",
    "                nn.BatchNorm1d(100),\n",
    "                nn.ReLU())\n",
    "        \n",
    "        self.l2 = nn.Sequential(\n",
    "                nn.Linear(100, 200),\n",
    "                nn.BatchNorm1d(200),\n",
    "                nn.ReLU())\n",
    "        self.l3 = nn.Sequential(\n",
    "                nn.Linear(200, 500),\n",
    "                nn.BatchNorm1d(500),\n",
    "                nn.ReLU())\n",
    "        self.l4 = nn.Sequential(\n",
    "                nn.Linear(500, 200),\n",
    "                nn.BatchNorm1d(200),\n",
    "                nn.ReLU())\n",
    "        self.l5 = nn.Sequential(\n",
    "                nn.Linear(200, 100),\n",
    "                nn.BatchNorm1d(100),\n",
    "                nn.ReLU())\n",
    "        self.logits = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.l1(x)\n",
    "        x2 = self.l2(x1)\n",
    "        x = self.l3(x2)\n",
    "        x = x2 + self.l4(x)\n",
    "        x = x1 + self.l5(x)\n",
    "        logits = self.logits(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f0d08765-2150-48a0-a1dc-1bd0ae14167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1d220893-1076-4e76-9296-2c642060938c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "space_finder(\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (l2): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (l3): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=500, bias=True)\n",
       "    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (l4): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (l5): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (logits): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = space_finder()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cfa3748b-af51-4f89-8b35-666434e0565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimentation\n",
    "# torch.manual_seed(42)\n",
    "# x = torch.rand((1,5,12), device = device)\n",
    "# y = model(x)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0c63bfa2-9ba6-4b13-8a20-af59712610a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b3fcdd56-1d45-4145-b5cd-b875722a5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_loop(i, see_batch_loss = False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    y_true = []\n",
    "    y_preds = []\n",
    "    for batch, (data, label) in enumerate(train_loader):\n",
    "        data , label = data.to(device), label.to(device)\n",
    "        # print(data.shape)\n",
    "        logits = model(data)\n",
    "        # preds = preds.argmax(dim = -1)\n",
    "        # print(logits)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits.view(-1), label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = torch.sigmoid(logits).view(-1) > 0.5\n",
    "        y_true.extend(label.cpu().tolist())\n",
    "        y_preds.extend(preds.detach().cpu().tolist())\n",
    "        \n",
    "        if see_batch_loss:\n",
    "            if batch%eval_train == 0:\n",
    "                print(f'Batch_Loss_{batch} : {loss.item()}')\n",
    "\n",
    "    if i%eval_train_test==0:\n",
    "        val_loss, val_acc = test_loop(test_loader)\n",
    "        print(f'Epoch {i+1}: train_loss: {(total_loss/len(train_loader)):.4f}, train_acc: {(accuracy_score(y_true, y_preds)):.4f}, val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}')\n",
    "        \n",
    "\n",
    "\n",
    "def test_loop(dataset):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        y_true = []\n",
    "        y_preds = []\n",
    "        for data, label in dataset:\n",
    "            data , label = data.to(device), label.to(device)\n",
    "            logits = model(data)\n",
    "    \n",
    "            loss = loss_fn(logits.view(-1), label)\n",
    "            \n",
    "            total_loss+=loss.item()\n",
    "            preds = torch.sigmoid(logits).view(-1) > 0.5\n",
    "            y_true.extend(label.cpu().tolist())\n",
    "            y_preds.extend(preds.detach().cpu().tolist())\n",
    "                              \n",
    "    return total_loss/len(test_loader), accuracy_score(y_true, y_preds)\n",
    "    # print(f'val_loss: {total_loss/len(test_loader)}, val_acc: {accuracy_score(y_true, y_preds)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "37869b60-094e-4bf7-a0f0-18d44b2afa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.3913, train_acc: 0.8105, val_loss: 0.4382, val_acc: 0.8061\n",
      "Total_time: 24.17899179458618\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(epoch): \n",
    "    train_loop(i)\n",
    "    # break\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(f'Total_time: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f6ffa-9b59-40bc-9a9b-b63c50c744d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I trained the model on the 5 layer mlp and the result was not that great i got stuck at 80% and I even trained it for 1000 epochs!\n",
    "# Now I will try to use skip connections, lets see..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4819c3b-2f10-4f0f-af67-181b03373500",
   "metadata": {},
   "source": [
    "#### Lets try a transformer model here!!!!\n",
    "1. First layer will be layer norm\n",
    "2. Second will be attention layer\n",
    "   1. First I will try for a single head attention\n",
    "   2. Multihead attention\n",
    "   3. multiblocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1efafccc-31ac-43c5-8528-37a3d1351ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e22d1dde-e616-4aeb-9fcd-4c321b64bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Head\n",
    "from torch.nn import functional as F\n",
    "class sa_layer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \n",
    "        super(sa_layer, self).__init__()\n",
    "        self.q = nn.Linear(channels, channels // 4, bias = False)\n",
    "        self.k = nn.Linear(channels, channels // 4, bias = False)\n",
    "        self.v = nn.Linear(channels, channels // 4, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "\n",
    "        wei = q @ k.transpose(0,1) * 100  ** -0.5\n",
    "        wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "        v = self.v(x)\n",
    "\n",
    "        out = wei @ v\n",
    "\n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3e2a6179-096e-490e-ac39-c9619274387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "torch.manual_seed(42)\n",
    "class space_finder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(space_finder, self).__init__()\n",
    "        self.l1 = nn.Linear(12, 128)\n",
    "        self.ln1 = nn.LayerNorm(128)\n",
    "        \n",
    "        self.sa1 = sa_layer(128)\n",
    "        self.sa2 = sa_layer(128)\n",
    "        self.sa3 = sa_layer(128)\n",
    "        self.sa4 = sa_layer(128)\n",
    "        \n",
    "        self.ln2 = nn.LayerNorm(128)\n",
    "\n",
    "        self.ffw = nn.Sequential(\n",
    "                    nn.Linear(128, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 128),\n",
    "        )\n",
    "\n",
    "        self.logits = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x0 = self.l1(x)\n",
    "        x = self.ln1(x0)\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x)\n",
    "        x3 = self.sa3(x)\n",
    "        x4 = self.sa4(x)\n",
    "\n",
    "        x5 = x0 + torch.cat([x1,x2,x3,x4], dim = -1)\n",
    "        \n",
    "        x = self.ln2(x5)\n",
    "\n",
    "        x = x5 + self.ffw(x)\n",
    "\n",
    "        logits = self.logits(x)\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4b293476-f97a-48e5-9cbf-33ea27a57e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter----\n",
    "\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "epoch = 100\n",
    "batch_eval_inter = 100\n",
    "eval_train_test = 10\n",
    "# eval_test = 10\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6e73e47e-f9d7-4cc1-8623-16dae49468f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "space_finder(\n",
       "  (l1): Linear(in_features=12, out_features=128, bias=True)\n",
       "  (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (sa1): sa_layer(\n",
       "    (q): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (k): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (v): Linear(in_features=128, out_features=32, bias=False)\n",
       "  )\n",
       "  (sa2): sa_layer(\n",
       "    (q): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (k): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (v): Linear(in_features=128, out_features=32, bias=False)\n",
       "  )\n",
       "  (sa3): sa_layer(\n",
       "    (q): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (k): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (v): Linear(in_features=128, out_features=32, bias=False)\n",
       "  )\n",
       "  (sa4): sa_layer(\n",
       "    (q): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (k): Linear(in_features=128, out_features=32, bias=False)\n",
       "    (v): Linear(in_features=128, out_features=32, bias=False)\n",
       "  )\n",
       "  (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffw): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (logits): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = space_finder()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "081abac0-f398-4296-a13b-1c81f63a1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "2e9a5e64-21eb-4d3c-a032-8ef1023af7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.5692, train_acc: 0.7043, val_loss: 0.5146, val_acc: 0.7485\n",
      "Epoch 11: train_loss: 0.4290, train_acc: 0.7947, val_loss: 0.4322, val_acc: 0.7879\n",
      "Epoch 21: train_loss: 0.4219, train_acc: 0.7985, val_loss: 0.4404, val_acc: 0.7985\n",
      "Epoch 31: train_loss: 0.4165, train_acc: 0.7985, val_loss: 0.4297, val_acc: 0.8197\n",
      "Epoch 41: train_loss: 0.4174, train_acc: 0.7940, val_loss: 0.4229, val_acc: 0.8167\n",
      "Epoch 51: train_loss: 0.4160, train_acc: 0.7955, val_loss: 0.4222, val_acc: 0.8015\n",
      "Epoch 61: train_loss: 0.4122, train_acc: 0.7995, val_loss: 0.4198, val_acc: 0.8061\n",
      "Epoch 71: train_loss: 0.4085, train_acc: 0.8005, val_loss: 0.4157, val_acc: 0.8136\n",
      "Epoch 81: train_loss: 0.4097, train_acc: 0.8012, val_loss: 0.4226, val_acc: 0.8045\n",
      "Epoch 91: train_loss: 0.4091, train_acc: 0.8005, val_loss: 0.4087, val_acc: 0.8091\n",
      "Total_time: 162.90756607055664\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(epoch): \n",
    "    train_loop(i)\n",
    "    # break\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(f'Total_time: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a364a92-56c3-41e5-9fa0-78edc8dfda5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
